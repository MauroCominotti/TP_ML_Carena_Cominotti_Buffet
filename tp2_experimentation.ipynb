{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zH_Kd00CwNdv"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/21971449/how-do-i-increase-the-cell-width-of-the-jupyter-ipython-notebook-in-my-browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.prompt { display:none !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fggOEw1ZsPtX"
   },
   "source": [
    "# Trabajo Práctico 2: Entrenamiento y evaluación de modelos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNVf73dvsZMx"
   },
   "source": [
    "## Fecha y hora de entrega máxima:\n",
    "09/05/2022 18:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJvBcdjAvLC0"
   },
   "source": [
    "## Dataset \"Datos de clientes del banco\"\n",
    "Los datos están relacionados con campañas de marketing directo (llamadas telefónicas) de una institución bancaria portuguesa. El objetivo de la clasificación es predecir si el cliente suscribirá un depósito a plazo.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/kaggle-datasets-images/864595/1473402/1f559c7d6d646d0a5f24c1847fb10225/dataset-cover.jpg?t=2020-09-08-19-15-14\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bf5c98e"
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import sklearn_pandas\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder, QuantileTransformer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7Y1hsJYPEmw"
   },
   "source": [
    "## **IMPORTANDO DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvqmm3FRx86O"
   },
   "outputs": [],
   "source": [
    "# To replace these values with NaN, we must provide a list with all missing value formats\n",
    "missing_value_formats = [\"unknown\", \"n.a.\",\"?\",\"NA\",\"n/a\", \"na\", \"--\"]\n",
    "dataset_original = pd.read_csv(\"BankCustomerData.csv\", na_values = missing_value_formats)\n",
    "# We will fill all NaN values with a string with value 'missing'\n",
    "dataset_original.fillna('missing', inplace=True)\n",
    "ds = dataset_original\n",
    "ds_feature_eng = dataset_original\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCV8wARQRV47"
   },
   "source": [
    "## **FEATURE ENGINEERING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3xutH2lRZNo"
   },
   "source": [
    "Nos parecio conveniente avanzar sin utilizar técnicas de feature engineering ya que entendemos que los datos del DS son lo suficientemente representativos. No vemos conveniente aplicar redondeos ya que las variables numéricas que tenemos (age, balance, duration) son de tipo entero. Tampoco observamos columnas que contengan información \"escondida\" que convenga extraerla para crear nuevas features.\n",
    "Por otro lado si hemos utilizado técnicas de pre-procesamiento como por ejemplo StandardScaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YlhOmP6QrLZ"
   },
   "source": [
    "### **Train, Validation and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P21irofNQOXZ"
   },
   "outputs": [],
   "source": [
    "ds[\"term_deposit\"] = ds.term_deposit.replace(['no', 'yes'], [0,1])\n",
    "#ds_feature_eng[\"term_deposit\"] = ds_feature_eng.term_deposit.replace(['no', 'yes'], [0,1])\n",
    "# Dividimos el dataset en train (60%), test (20%) y validation (20%)\n",
    "train, not_train = train_test_split(ds, test_size=0.4, random_state=42)\n",
    "validation, test = train_test_split(not_train, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfnZWo5osCa0"
   },
   "source": [
    "## **MÉTRICA A UTILIZAR**\n",
    "La métrica que utilizaremos es **Precission**, ya que, errar por si o por no tiene diferente impacto en este problema. Nos interesa tener cierta seguridad de que a la hora de llamar a un cliente para ofrecerle un depósito a plazo, exista un alto porcentaje de que este quiera avanzar en el proceso. De esta manera evitamos generar cierto rechazo y mal estar del cliente hacia la organización.\n",
    "\n",
    "Por otra parte, también utilizaremos la métrica **Accuracy**, la cual mide el porcentaje de casos que el modelo ha acertado. Esta es una de las métricas más usadas, es sencillo de explicar al usuario final que requiere el modelo, y es oportuna para casos de clasificación. \n",
    "\n",
    "Sin embargo nos puede llevar al engaño, es decir, puede hacer que un modelo malo parezca que es mucho mejor de lo que realmente es, es por ésto que también tenemos a **Precission**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moV0E4NnP_18"
   },
   "source": [
    "## **MAPPING DE VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6bm-gzZ5fO5"
   },
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    (['age'],[StandardScaler()]),\n",
    "    (['loan'],[OneHotEncoder()]),\n",
    "    (['housing'],[OneHotEncoder()]),\n",
    "    (['job'],[OneHotEncoder()]),\n",
    "    (['education'],[OneHotEncoder()]),\n",
    "    (['balance'],[StandardScaler()])\n",
    "])\n",
    "mapper.fit(train)\n",
    "mapper.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63QpN4arysll"
   },
   "source": [
    "## ENTRENAMIENTO DE MODELOS\n",
    "Elegimos los siguientes 6 modelos para entrenar:\n",
    "- Logistic Regression\n",
    "- Arbol de Decisión\n",
    "- Random Forest\n",
    "- Gradient Boosting Classifier\n",
    "- KNN\n",
    "- Neural Networks MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f0FqN1MR6Sx"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, set_names=('train', 'validation'), title='', is_feature_engineering=False, show_confusion_matrix=True):\n",
    "    if title:\n",
    "        display(title)\n",
    "    metrics_to_show = defaultdict(list)\n",
    "    if show_confusion_matrix:\n",
    "        fig, axis = plt.subplots(1, len(set_names), sharey=True, figsize=(15, 3))\n",
    "    for i, set_name in enumerate(set_names):\n",
    "        if is_feature_engineering:\n",
    "          assert set_name in ['train', 'validation', 'test']\n",
    "        set_data = globals()[set_name]\n",
    "        y = set_data.term_deposit\n",
    "        y_pred = model.predict(set_data)\n",
    "        metrics_to_show['Accuracy'].append(accuracy_score(y, y_pred))\n",
    "        metrics_to_show['Precision'].append(precision_score(y, y_pred))\n",
    "        if show_confusion_matrix:\n",
    "            ax = axis[i]\n",
    "            sns.heatmap(confusion_matrix(y, y_pred), ax=ax, cmap='Blues', annot=True, fmt='.0f', cbar=False)\n",
    "\n",
    "            ax.set_title(set_name)\n",
    "            ax.xaxis.set_ticklabels(['No se suscribe', 'Se suscribe'])\n",
    "            ax.yaxis.set_ticklabels(['No se suscribe', 'Se suscribe'])\n",
    "            ax.set_xlabel('Clase Predecida')\n",
    "            ax.set_ylabel('Clase Original')\n",
    "\n",
    "    display(pd.DataFrame(metrics_to_show, index=set_names))\n",
    "    if show_confusion_matrix:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM0HH26UR8op"
   },
   "source": [
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eR53dg2dR7iT"
   },
   "outputs": [],
   "source": [
    "model_logistic_regression = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', LogisticRegression(random_state=100)),\n",
    "])\n",
    "model_logistic_regression.fit(train, train.term_deposit)\n",
    "evaluate_model(model_logistic_regression, title='Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIL6ZDYbcUE9"
   },
   "source": [
    "Podemos ver que tenemos un ratio de clasificación del 90.8% en train, y del 90.7 en validation, considerado como **buen accuracy.**\n",
    "\n",
    "En cuanto a **precission**, podemos ver que es del 0%, con lo cual, o tiene datos que no \"contienen\" suficiente información para predecir la clase y el clasificador simplemente \"adivina\" la clase más frecuente. O bien tenemos muchos más datos de clase 1 que de clase 0 que la precisión es mejor si siempre adivina 1 en lugar de tratar de clasificar correctamente (como tenemos más term_deposit=\"no\" que \"yes\", adivina siempre \"no\").\n",
    "\n",
    "Cosas que podríamos hacer: \n",
    "1. Intentar obtener más datos de clase \"si\" (term_deposit=\"yes\") de algún lugar.\n",
    "2. Probar con otro clasificador que encaje mejor que la regresión logística.\n",
    "3. Intentar obtener más y mejores datos, de diferentes fuentes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ow4TmI2isPWD"
   },
   "source": [
    "### **Arbol de Decisión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpPLiMZEsVLh"
   },
   "outputs": [],
   "source": [
    "model_tree_decision = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth = 7, random_state=100)),\n",
    "])\n",
    "model_tree_decision.fit(train, train.term_deposit)\n",
    "evaluate_model(model_tree_decision, title='Arbol de Decisión')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHVzgyvpf15h"
   },
   "source": [
    "Podemos ver que tenemos un ratio de clasificación del 90.9% en train, y del 90.6 en validation, considerado como **buen accuracy.**\n",
    "\n",
    "En cuanto a **precission**, de todas las veces que predice un resultado, el 78% de las veces está en lo correcto en train, y el 38% de las veces está en lo correcto en validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZReFLP-j7Tf"
   },
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBo-IsTOj7F8"
   },
   "outputs": [],
   "source": [
    "model_random_forest = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', RandomForestClassifier(random_state=100)),\n",
    "])\n",
    "model_random_forest.fit(train, train.term_deposit)\n",
    "evaluate_model(model_random_forest, title='Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7fBeUr6lnV7"
   },
   "source": [
    "Hay overfitting, para esto modificamos los hyperparametros dandole más profundidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWnqqizYltp0"
   },
   "outputs": [],
   "source": [
    "model_random_forest_modified = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=15, max_features=15, random_state=100)),\n",
    "])\n",
    "model_random_forest_modified.fit(train, train.term_deposit)\n",
    "evaluate_model(model_random_forest_modified, title='Random Forest with Depth = 15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6uoQjdJyoMw"
   },
   "source": [
    "### **Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zy81SYy2ypHZ"
   },
   "outputs": [],
   "source": [
    "model_gradient_boosting = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42)),\n",
    "])\n",
    "model_gradient_boosting.fit(train, train.term_deposit)\n",
    "evaluate_model(model_gradient_boosting, title='Gradient Boosting Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YTIuiWEj2_2"
   },
   "source": [
    "Podemos ver que tenemos un ratio de clasificación del 91% en train, y del 90.7 en validation, considerado como **buen accuracy.**\n",
    "\n",
    "En cuanto a **precission**, de todas las veces que predice un resultado, el 94% de las veces está en lo correcto en train, y el 40% de las veces está en lo correcto en validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE9OQke9fM2G"
   },
   "source": [
    "### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LLsflFfn_Ns"
   },
   "outputs": [],
   "source": [
    "model_knn = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=3)),\n",
    "])\n",
    "model_knn.fit(train, train.term_deposit)\n",
    "evaluate_model(model_knn, title='K Nearest Neighbors with K = 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpB-cmeKfN8N"
   },
   "outputs": [],
   "source": [
    "model_knn = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=10)),\n",
    "])\n",
    "model_knn.fit(train, train.term_deposit)\n",
    "evaluate_model(model_knn, title='K Nearest Neighbors with K = 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtofK89FXfOv"
   },
   "source": [
    "### **Neural Network MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f-JqsM3XfOv"
   },
   "outputs": [],
   "source": [
    "model_mlp_classifier = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=(20,10),max_iter=20, random_state=42)),\n",
    "])\n",
    "model_mlp_classifier.fit(train, train.term_deposit)\n",
    "evaluate_model(model_mlp_classifier, title='MLP Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbipbpaYXfOv"
   },
   "source": [
    "Con modelo de MLP Classifier se obtiene un resultado bastante bueno aunque no mejor que los demás modelos. Tambien vemos que el mismo no mejora mas aumentando la cantidad de capas ocultas o la cantidad de iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2vNABaUpzg3"
   },
   "source": [
    "## OVERFITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0DCcKPgUHKx"
   },
   "outputs": [],
   "source": [
    "def generate_curve(selected_model=\"DecisionTree\", list_to_iterate=list(range(1, 17))):\n",
    "  train_prediction =  []\n",
    "  eval_prediction = []\n",
    "  for x in list_to_iterate:\n",
    "    models = {\n",
    "                \"DecisionTree\": Pipeline([\n",
    "                  ('mapper', mapper),\n",
    "                  ('classifier', DecisionTreeClassifier(max_depth=x, random_state=100)),\n",
    "                ]),\n",
    "                \"RandomForest\": Pipeline([\n",
    "                  ('mapper', mapper),\n",
    "                  ('classifier', RandomForestClassifier(n_estimators=100, max_depth=x, max_features=15, random_state=100)),\n",
    "                ]),\n",
    "                \"KNN\": Pipeline([\n",
    "                  ('mapper', mapper),\n",
    "                  ('classifier', KNeighborsClassifier(n_neighbors=x)),\n",
    "                ]),\n",
    "                \"MLPClassifier\": Pipeline([\n",
    "                  ('mapper', mapper),\n",
    "                  ('classifier', MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=(20,10),max_iter=x, random_state=42)),\n",
    "                ]),\n",
    "                \"GradientBoosting\": Pipeline([\n",
    "                    ('mapper', mapper),\n",
    "                    ('classifier', GradientBoostingClassifier(learning_rate=x, max_depth=5, max_features=15, random_state=100)),\n",
    "                ])\n",
    "              }\n",
    "    model = models[selected_model]\n",
    "    model=model.fit(train, train.term_deposit)    \n",
    "    train_prediction.append(model.score(train, train.term_deposit))\n",
    "    eval_prediction.append(model.score(validation, validation.term_deposit))\n",
    "  plt.plot(list_to_iterate, train_prediction, color='r', label='Train')\n",
    "  plt.plot(list_to_iterate, eval_prediction, color='b', label='Validation')\n",
    "  plt.title('Grafico ' + selected_model)\n",
    "  plt.legend()\n",
    "  plt.ylabel('Precisión')\n",
    "  plt.xlabel('Cantidad de vecinos')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX8CKScNTGLR"
   },
   "source": [
    "### Curva para Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW4o4jSwTIoM"
   },
   "outputs": [],
   "source": [
    "generate_curve(\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atsTsKglTI7e"
   },
   "source": [
    "Como podemos ver en el gráfico anterior, entre una profundidad de 2 a 8 se encuentra el valor más eficiente para el algoritmo KNN. Luego de ésto podemos ver como ambas líneas divergen hacia los extremos, en el caso de train overfitea hacia el 100% y en el caso de validation deja de aprender, y cae hacia el 0%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tIfSt8sSzFd"
   },
   "source": [
    "### Curva para Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzlJitIyTDwV"
   },
   "outputs": [],
   "source": [
    "generate_curve(\"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZFXchUITELt"
   },
   "source": [
    "### Curva para Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhmlssMOgvpF"
   },
   "outputs": [],
   "source": [
    "generate_curve(\"GradientBoosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFYPjCnokjyv"
   },
   "source": [
    "Como podemos ver en el gráfico anterior, tenemos picos de precisión asignando un learning rate de 1, 6, 8 y 15, encontrando así en éstos puntos el valor más eficiente para el algoritmo Gradient Boosting. Luego de ésto podemos ver como ambas líneas tienen valles en el resto de números."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-fnv9ztSqnJ"
   },
   "source": [
    "### Curva para KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uo82bUIUp1Sa"
   },
   "outputs": [],
   "source": [
    "generate_curve(\"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyJnTH--Kp"
   },
   "source": [
    "Como podemos ver en el gráfico anterior, entre un K de 4 a 8 se encuentra el valor más eficiente para el algoritmo KNN. Luego de ésto podemos ver como ambas líneas convergen hacia el 0.91 aproximadamente, es decir se estancan y deja de aprender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHYHK9H6XfOx"
   },
   "source": [
    "### Curva para MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3AYItp9XfOx"
   },
   "outputs": [],
   "source": [
    "generate_curve(\"MLPClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vquXG_MeXfOx"
   },
   "source": [
    "Vemos que el modelo MLP Classifier no esta overfitiando ya que la métrica seleccionada no tiene grandes cambios entre Train y Validation y tambien viendo que la curva  de aprendizaje no varia en las primeras 10 iteraciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auxEnx0q24Vh"
   },
   "source": [
    "## COMPARACIÓN FINAL ENTRE LOS DISTINTOS MODELOS\n",
    "Comparación entre:\n",
    "- Logistic Regression\n",
    "- Arbol de Decisión\n",
    "- Random Forest\n",
    "- Gradient Boosting Classifier\n",
    "- KNN\n",
    "- Neural Networks MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18T2v-WB3Mpo"
   },
   "outputs": [],
   "source": [
    "evaluate_model(model_logistic_regression, title='Logistic Regression', set_names=('train', 'validation', 'test'), is_feature_engineering=False, show_confusion_matrix=False)\n",
    "evaluate_model(model_tree_decision, title='Arbol de Decisión', set_names=('train', 'validation', 'test'), is_feature_engineering=False, show_confusion_matrix=False)\n",
    "evaluate_model(model_random_forest_modified, title='Random Forest with Depth = 15', set_names=('train', 'validation', 'test'), is_feature_engineering=False, show_confusion_matrix=False)\n",
    "evaluate_model(model_gradient_boosting, title='Gradient Boosting Classifier', set_names=('train', 'validation', 'test'), is_feature_engineering=False, show_confusion_matrix=False)\n",
    "evaluate_model(model_knn, title='K Nearest Neighbors with K = 6', set_names=('train', 'validation', 'test'), is_feature_engineering=False, show_confusion_matrix=False)\n",
    "evaluate_model(model_mlp_classifier, title='MLPClassifier', set_names=('train', 'validation', 'test'), is_feature_engineering=False, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CABcZrF89x4"
   },
   "source": [
    "A raíz de los resultados obtenidos en los distintos modelos en relación a la métrica precission observamos que en general no obtuvimos buenos resultados logrando con Random Forest un porcentaje aceptable, aunque con este mismo vemos que el modelo overfitea bastante.\n",
    "Con Gradient Boosting vemos un resultado similar de 0.52 aproximadamente y al igual que Random Forest la diferencia entre el dataset de train y los dataset de validación es notoria.\n",
    "Con el modelo de redes neuronales Multi Layer Perceptron los resultados no son tan malos y aunque luego de modificar los hyperparametros fue mejorando pero no llegamos a lograr los resultados esperados.\n",
    "Finalmente optamos por el Gradient Boosting ya que en promedio entre test y validation nos pareció mas eficiente."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tp2_experimentation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
